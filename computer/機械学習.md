![](/picture/機械学習1.png)

### 形式ニューロン
実際のニューロン（神経）の活動をモデル化したもの。ピッツモデルとも呼ばれる。
![](/picture/機械学習2.png)
  
- `x0`： バイアス（これを閾値と説明するものもある）
- `xi`： 入力
- `wi`： 重み。
- `H`: ヘヴィサイドの階段関数（ステップ関数）と呼ばれ、閾値である0を超えていれば1、でなければ0を返却する。

### パーセプトロン
形式ニューロンの考え方をベースにした実装全般を指す。

- 単純パーセプトロン  
入力層と出力層の二層で構成されるパーセプトロン。
文脈によるが、ステップ関数を用いた実装を指すことが多い。

- 多層パーセプトロン（MLP）  
入力層、隠れ層、出力層の三層以上で構成されるパーセプトロン。ニューラルネットワークと呼ばれる。
基本的なものでは、各層間に重みがあり、隠れ層では非線形関数による変換が行われ、出力層は（ステップ関数などは用いず）単に隠れ層の総和となる。
![](/picture/機械学習3.png)
理論上、多層にすると人間の脳レベルの処理をできるが、設定すべき隠れ層の数、重み、非線形関数を導くロジックが複雑かつ膨大で、実質不可能であった。
しかし近年になって、ディープラーニングと呼ばれる機械学習アルゴリズムが開発され、それによって高い精度で設定できるようになってきた。


### ディープラーニング
主にニューラルネットワークベースのモデルを生成可能な機械学習アルゴリズムを指すが、抽象化して「対象の全体像から細部までの各々の粒度の概念を階層構造として関連させて学習する手法」とも定義される。

### 評価指標
- 回帰
  - RMSE（Root Mean Squared Error: 平均平方二乗誤差）
  - RMSLE（Root Mean Squared Logarithmic Error）
  - MAE（Mean Absolute Error）
  - 決定係数（R2）
- 二値分類〜正例か負例かを予測値とする場合
  - accuracy（正答率）
  - error rate（誤答率）
  - precision（適合率）
    - 正例と予測したもののうちの正解率。負例を正例と誤答したくないときに重要視する指標。正例と予測する判定を厳しくすればスコアは高くなる。
  - recall（再現率）
    - 正解が正例のもののうち、正例と予測できた割合。正例を取りこぼしたくないときに重要視する指標。正例と予測する判定を甘くすればスコアは高くなる。
  - F1-score
  - Fβ-score
  - MCC（Matthews Correlation Coefficient）
- 二値分類〜正例である確率を予測値とする場合
  - logloss
  - AUC（Area Under the ROC Curve）
- 多クラス分類
  - multi-class accuracy
  - multi-class logloss
  - mean-F1
  - macro-F1
  - micro-F1
  - quadratic weighted kappa
  - balanced accuracy
- レコメンデーション
  - MAP@K（Mean Average Precision）

### 目的関数
モデルが学習において分岐や係数の追加/削除の判断基準に使う関数のこと。評価指標と同じ関数を使うことがある（RMSEやloglossなど）。


### 調和平均
生産性や能力の平均を求めるときに使う。
```
aとbの調和平均 = 2 / （1/a + 1/b）
```
通常の平均（相加平均）は量を元に計算している（40個と60個の平均は50個）。

生産性や能力とは、単位あたりに出力できる量を表現している。例えば`5km/h`の能力は1時間あたり5kmを、`10km/h`の能力は1時間あたり10kmを出力できることを表している。

これらの能力の平均を求めるとする。ポイントはそれぞれの能力を発揮した時間の情報が無いこと、つまり出力量を算出できないため相加平均は使えない。そのため調和平均では、能力を単位と出力量に分解・セットにして考える。

※もし、能力を発揮した時間がわかっている場合は、先に出力量を算出して相加平均すれば良い。例えば`5km/h`で1時間、`10km/h`で1時間で移動したときの平均速度は`7.5km/h`で良い。

`5km/h`は1kmあたり1/5時間かかることを表す。`10km/h`の場合は1kmあたり1/10時間かかる。それぞれの能力を順に発揮したとすると、1/5 ＋ 1/10時間で2kmの結果を出したことになる。これを1つの能力とみなす（調和平均をとる）と`2 / (1/5 + 1/10) = 6.67`となる。　　

このように能力に関する計算は、量と単位に分解・セットにして考える必要がある。

平均を求める対象が能力の場合には、調和平均を用いることが正しく、それによってモデルの学習結果の向上が見込める。

### 線形変換
変数の分布は伸縮するだけで形状そのものは変わらない（乗算と加算のみによる変換）。

- 標準化  
平均を0、標準偏差を1にする線形変換のこと。
```
x' = (x - μ)/σ
```
![](../picture/機械学習_標準化.png)
分子と分母の単位が同じであれば、それは割合を表す。`30人/500人 ＝ 0.06 = 6%の人 = 3000人/50000人`

標準化は偏差を標準偏差で割っている（分子と分母の単位が同じ）ため、平均値からのバラつき率とも言える。
従って変換前の値の大小に関係なく（変数AでもBでも）`-2〜2`付近の値になる仕組み。

- 正規化  
全てのデータが0～1の間の大きさに変換すること。Min-Maxスケーリングともいう。

### 非線形変換
変数の分布の形状を変える。

- 対数変換  
![](../picture/機械学習_対数.png)
底や真数が1より大きいかどうかによって値変化の特徴が変わるため、必要に応じて使い分ける。
![](../picture/機械学習_対数2.jpeg)

- Box-Cox変換

- Yeo-Johnson変換
- generalized log transformation
- その他の非線形変換
  - 絶対値を取る
  - 平方根を取る
  - 2乗を取る、n乗を取る
  - 正の値かどうか、ゼロかどうかなどの二値変数とする
  - 数値の端数をとる
  - 四捨五入・切り上げ・切り捨て


### RankGauss
データを順位に変換した上で正規分布になるように変換する手法。ニューラルネットで良い性能を示す。元のデータが多峰であっても正規分布にできる。

