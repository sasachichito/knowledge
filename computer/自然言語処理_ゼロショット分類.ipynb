{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbtiFRka2i415owNtKGf1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sasachichito/knowledge/blob/master/computer/%E8%87%AA%E7%84%B6%E8%A8%80%E8%AA%9E%E5%87%A6%E7%90%86_%E3%82%BC%E3%83%AD%E3%82%B7%E3%83%A7%E3%83%83%E3%83%88%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 依存関係"
      ],
      "metadata": {
        "id": "Fhf2x5jc5r-7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfLhDu_U5eYN",
        "outputId": "a83919d9-be94-49e5-8732-c636afafe7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[ja] in /usr/local/lib/python3.10/dist-packages (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (0.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[ja]) (4.66.4)\n",
            "Collecting fugashi>=1.0 (from transformers[ja])\n",
            "  Downloading fugashi-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (600 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m600.9/600.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic<2.0,>=1.0.0 (from transformers[ja])\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidic-lite>=1.0.7 (from transformers[ja])\n",
            "  Downloading unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidic>=1.0.2 (from transformers[ja])\n",
            "  Downloading unidic-1.1.0.tar.gz (7.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sudachipy>=0.6.6 (from transformers[ja])\n",
            "  Downloading SudachiPy-0.6.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sudachidict-core>=20220729 (from transformers[ja])\n",
            "  Downloading SudachiDict_core-20240409-py3-none-any.whl (72.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rhoknp<1.3.1,>=1.1.0 (from transformers[ja])\n",
            "  Downloading rhoknp-1.3.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[ja]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers[ja]) (4.11.0)\n",
            "Collecting wasabi<1.0.0,>=0.6.0 (from unidic>=1.0.2->transformers[ja])\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting plac<2.0.0,>=1.1.3 (from unidic>=1.0.2->transformers[ja])\n",
            "  Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja]) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[ja]) (2024.2.2)\n",
            "Building wheels for collected packages: ipadic, unidic, unidic-lite\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556704 sha256=d2885ca04cfab28285e77f8e70b47661f457d2739c9a4a2608837ce7966bb66b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for unidic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic: filename=unidic-1.1.0-py3-none-any.whl size=7406 sha256=bd0b18b8e7ce738c4ce3a99f0ec162c846a5344d199ba4af28a21399f136e655\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/72/72/1f3d654c345ea69d5d51b531c90daf7ba14cc555eaf2c64ab0\n",
            "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unidic-lite: filename=unidic_lite-1.0.8-py3-none-any.whl size=47658818 sha256=78141ee39dd745f073003693723ec2794c0b977228afa4448b262a7710c7e944\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/e8/68/f9ac36b8cc6c8b3c96888cd57434abed96595d444f42243853\n",
            "Successfully built ipadic unidic unidic-lite\n",
            "Installing collected packages: wasabi, unidic-lite, sudachipy, plac, ipadic, sudachidict-core, rhoknp, fugashi, unidic\n",
            "  Attempting uninstall: wasabi\n",
            "    Found existing installation: wasabi 1.1.2\n",
            "    Uninstalling wasabi-1.1.2:\n",
            "      Successfully uninstalled wasabi-1.1.2\n",
            "Successfully installed fugashi-1.3.2 ipadic-1.0.0 plac-1.4.3 rhoknp-1.3.0 sudachidict-core-20240409 sudachipy-0.6.8 unidic-1.1.0 unidic-lite-1.0.8 wasabi-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers[ja]\n",
        "\n",
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def webpage_to_text(url, selector):\n",
        "  text = ''\n",
        "  with urlopen(url) as res:\n",
        "      html = res.read().decode('UTF-8', 'ignore')\n",
        "      soup = BeautifulSoup(html, 'html.parser')\n",
        "      # article = soup.find('div', class_=\"articleBody\")\n",
        "      # text = article.get_text(strip=True)\n",
        "      article = soup.select(selector)\n",
        "      text = ''\n",
        "      for p in article:\n",
        "        text += p.get_text(strip=True)\n",
        "      return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ゼロショット分類ライブラリ比較"
      ],
      "metadata": {
        "id": "CdW4JLni6R7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "\n",
        "classifier_mDeBERT = pipeline(\"zero-shot-classification\",model=\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\", device=device)\n",
        "texts = [\"今日、新しいiPhoneが発売されました\"]\n",
        "labels = [\"スマートフォン\", \"エンタメ\", \"スポーツ\"]\n",
        "result_md = classifier_mDeBERT(texts, labels, hypothesis_template=\"このニュースは{}に関する文章です.\")\n",
        "print(result_md)\n",
        "\n",
        "classifier_bart = pipeline(\"zero-shot-classification\",model=\"facebook/bart-large-mnli\", device=device)\n",
        "texts = [\"Darth Vader\"]\n",
        "labels = [\"Star Wars\", \"Star Trek\"]\n",
        "result_b = classifier_bart(texts, labels, hypothesis_template=\"This person is in {}.\")\n",
        "print(result_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-Eew6Or6Ux5",
        "outputId": "8179827f-890a-4af9-a6b1-dd10404bdbfd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'sequence': '今日、新しいiPhoneが発売されました', 'labels': ['スマートフォン', 'エンタメ', 'スポーツ'], 'scores': [0.9712119102478027, 0.023089371621608734, 0.00569870974868536]}]\n",
            "[{'sequence': 'Darth Vader', 'labels': ['Star Wars', 'Star Trek'], 'scores': [0.9938298463821411, 0.006170147098600864]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パイプラインから実行(日本語)"
      ],
      "metadata": {
        "id": "DtB0zDs_fRKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "classifier_mDeBERT = pipeline(\"zero-shot-classification\",model=\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\", device=device)\n",
        "\n",
        "sentence = 'HOME/AINOW編集部/Google I/O 2024におけるAI発表まとめ#Gemini#Google I/O#特集記事2024.05.28Google I/O 2024におけるAI発表まとめ最終更新日：2024年5月28日Google I/O 2024基調講演に登場したスンダ―・ピチャイGoogle CEO。画像出典：Googleブログ記事目次はじめにサマリーGeminiファミリーのアップデートとその活用軽量な1.5 Flash、アップデートしたGemini 1.5 Pro、先進的なProject Astraさらに多機能になる生成検索Gemini 1.5 Proをフル活用するGemini for Google Workspaceその他のGemini活用アプリAIによるAndroidの進化クリエイティブAIの進化ImageFXとImagen 3MusicFXと音楽業界とのコラボレーションVideoFXとVeoVeoとSoraの違い4人のアーティストと「不思議の国のアリス」を生成AIで再構築AI開発者のためのAIGemma 2とPaliGemmaデロリアンが授与されるGemini API デベロッパーコンペティション多数のAI開発ツールが発表＆アップデート第6世代AI用ハードウェア「Trillium」責任あるAIの取り組み拡張されるSynthID社会貢献のためのAIまとめはじめにGoogle主催の開発者カンファレンスGoogle I/O 2024が、日本時間2024年5月15日（アメリカ現地時間5月14日）から2日間の日程で開催されました。OpenAIがGPT-4oを発表した直後に開催された同カンファレンスでは、予想通りGoogleのAI開発に関する新情報が大量に発表されました。本記事では、Google I/O 2024で発表されたGoogleのAI技術とサービスに関する新情報をほぼ網羅的にまとめます。これらの情報はUS版Google公式ブログに設けられた「I/O 2024」関連ブログ記事集を参照したものであり、以下の各見出しの末尾には出典記事を明記します。日本語訳のある記事については、日本語訳記事を出典とします。参考記事：Google I/O 2022で発表された最新自然言語処理技術まとめAIによって自社を全方位的にアップデートしたGoogle I/O 2023まとめサマリー本記事の各見出しで解説する内容は、以下の表のようにまとめられます。見出し名キーワードGeminiファミリーのアップデートとその活用軽量なGemini 1.5 Flash、コンテキストウィンドウを200万にアップデートしたGemini 1.5 Pro、リアルタイム動画による対話を実現したProject Astra、多機能な生成検索AI Overviews、Geminiと連携するGemini for Google Workspace、Gemini 1.5 Proを採用したGemini Advanced、Geminiと対話できるGoogleメッセージ、Geminiと音声で話せるGemini LiveAIによるAndroidの進化教育用AI「LearnLM」と連携するかこって検索、Geminiと連携するオーバーレイ機能・TalkBack、Gemini Nanoの搭載、AIによる詐欺電話の検出、AIが画像を選定するAsk Photos、AIによる盗難防止・詐欺アプリ検出クリエイティブAIの進化画像編集が可能となったImageFX、最新画像生成モデルImagen 3、DJモードを追加したMusicFX、Music AI Sandboxによる音楽業界とのコラボレーション、動画生成アプリVideoFX、Soraに匹敵する動画生成モデルVeo、生成AI時代における実験的アート作品「無限な不思議の国」AI開発者のためのAI軽量かつ高性能なオープンソースモデルGemma 2、最新視覚言語オープンソースモデルPaliGemma、デロリアンが授与されるGeminiAPIデベロッパーコンペティション、AIの安全性を評価するLLM Comparator第6世代AI用ハードウェア「Trillium」前世代よりパフォーマンスが4.7倍となったTPU「Trillium」責任あるAIの取り組みテキストと動画に拡張されるSynthID、LearnLMを活用した教育アプリIlluminateとLearn about、機械学習アルゴリズムによる人間の脳の3D再構築、DNAやRNAも予測可能となったAlphaFold 3、医療に特化したMed-GeminiGeminiファミリーのアップデートとその活用Google I/O 2024においてもっとも重要な発表は、Googleが展開するAIビジネスの根幹となる基盤モデルGeminiのアップデート情報です。以下では、新しい2つのGeminiモデルとGeminiを活用したサービスとアプリをまとめます。軽量な1.5 Flash、アップデートしたGemini 1.5 Pro、先進的なProject AstraGeminiファミリーに効率性を重視したGemini 1.5 Flashが加わりました。​'\n",
        "\n",
        "texts = [sentence]\n",
        "labels = [\"AI\", \"未来\", \"テクノロジー\", \"アーキテクチャ\", \"ビジネス\", \"スポーツ\", \"エンタメ\"]\n",
        "\n",
        "# 長い入力は内部でトランケイトされる模様\n",
        "result_md = classifier_mDeBERT(texts, labels, hypothesis_template=\"このニュースは{}に関する文章です.\", multi_label=True)\n",
        "print(result_md[0].get(\"labels\"))\n",
        "print(result_md[0].get(\"scores\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q--xKiEfZ2J_",
        "outputId": "bbc67be8-b5bb-47af-c26c-d5fcf146fed5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['テクノロジー', 'AI', '未来', 'アーキテクチャ', 'ビジネス', 'エンタメ', 'スポーツ']\n",
            "[0.999890923500061, 0.9997818470001221, 0.9997126460075378, 0.9996882677078247, 0.9833944439888, 0.0002405198902124539, 6.651310832239687e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "パイプラインから実行（英語）"
      ],
      "metadata": {
        "id": "wq6R1d5NgFjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "classifier_mDeBERT = pipeline(\"zero-shot-classification\",model=\"MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7\", device=device)\n",
        "\n",
        "sentence = 'Michael Cohen implicated his former bossDonald Trumpin the hush money scheme to pay Stormy Daniels just days before the 2016 election, saying he doled out $130,000 at Trump’s direction and was promised reimbursement.Cohen’s testimony ties together the prosecution’s allegations that Trump broke the law by falsifying business records to reimburse Cohen and conceal the hush money payment that Cohen said he made at Trump’s direction. Trump has pleaded not guilty and denies having an affair with Daniels.Related live-storyMichael Cohen testifies in Trump hush money trialCohen and Trump mostly avoided eye contact while he testified Monday. Cohen looked directly at prosecutor Susan Hoffinger throughout most of his testimony, occasionally scanning the room or looking in the jury’s direction.'\n",
        "# sentence = '''On May 13, 2024, US time, US OpenAI held an online new product launch event and announced the next-generation AI (artificial intelligence) model \"GPT-4o\". It is a flagship model that will succeed the current model \"GPT-4 turbo\". The keyword is \"speed\". It will enable real-time dialogue between AI and voice. With OpenAI's new move, \"speed\" and \"usability\" are likely to emerge as the next competitive axis for AI models. The \"o\" in GPT-4o comes from the prefix \"omni\", which means \"all\". It can accept any combination of text, voice, images, etc. as input and output. What OpenAI particularly emphasized at the launch event was the improvement of voice dialogue performance. Although voice mode was available in \"ChatGPT\", which used conventional models such as GPT-4, there were issues with waiting time (latency). The average latency was 2.8 seconds for GPT-3.5 and 5.4 seconds for GPT-4. GPT-4o reduced this to an average of 0.32 seconds. The breakthrough was in the model's learning method. Models prior to GPT-4o supported voice mode by combining three independent models. The first model transcribed the voice as text, the second model took in the text and output the answer as text, and the third model converted the text to voice. Because it was converted to text once, it was not possible to incorporate information such as tone of voice or conversations by multiple speakers, and emotions could not be expressed as output. In contrast, GPT-4o is a model trained by combining visual information such as images and videos, text, and voice. By changing the learning method, it achieved low latency and acquired new capabilities to take emotions into account.'''\n",
        "\n",
        "texts = [sentence]\n",
        "# labels = [\"AI\", \"未来\", \"テクノロジー\", \"アーキテクチャ\", \"ビジネス\", \"スポーツ\", \"エンタメ\"]\n",
        "labels = [\"未来\", \"政治\"]\n",
        "result_md = classifier_mDeBERT(texts, labels, hypothesis_template=\"このニュースは{}に関する文章です.\", multi_label=True)\n",
        "print(result_md[0].get(\"labels\"))\n",
        "print(result_md[0].get(\"scores\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qV82NxmqgIMH",
        "outputId": "c12db087-7b3b-4158-8fe9-6c8f4481ac6f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['政治', '未来']\n",
            "[0.9821041822433472, 0.0034678068477660418]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "マニュアル操作"
      ],
      "metadata": {
        "id": "cPGiE64kfNTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n",
        "\n",
        "sentence = 'Who are you voting for in 2020?'\n",
        "labels = ['business', 'art & culture', 'politics']\n",
        "\n",
        "premise = sentence\n",
        "hypothesis = f'This example is {labels[2]}.' # ラベル'politics'の確率を調べる\n",
        "\n",
        "# run through model pre-trained on MNLI\n",
        "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
        "                     truncation_strategy='only_first')\n",
        "print(tokenizer.decode(x.flatten()))\n",
        "print(x)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  x = x.cuda()\n",
        "  nli_model = nli_model.cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  logits = nli_model(x)[0]\n",
        "print(logits)\n",
        "\n",
        "# ロジットのうち、含意（entailment）のロジット（インデックス2）と矛盾（contradiction）のロジット（インデックス0）を抽出します。中立（neutral）のロジット（インデックス1）は無視します。\n",
        "entail_contradiction_logits = logits[:,[0,2]]\n",
        "print(entail_contradiction_logits)\n",
        "\n",
        "# 出したロジットに対してソフトマックス関数を適用し、確率を計算します。\n",
        "probs = entail_contradiction_logits.softmax(dim=1)\n",
        "print(probs)\n",
        "\n",
        "# ソフトマックス後の含意（entailment）の確率を取り出します。この確率が、ラベルが正しい確率として解釈されます。\n",
        "prob_label_is_true = probs[:,1]\n",
        "print(prob_label_is_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noT0ucDRQfw1",
        "outputId": "1240c8d7-5cea-45a9-87ae-54654b3b31b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2734: FutureWarning: The `truncation_strategy` argument is deprecated and will be removed in a future version, use `truncation=True` to truncate examples to a max length. You can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to truncate to the maximal input size of the model (e.g. 512 for Bert).  If you have pairs of inputs, you can give a specific truncation strategy selected among `truncation='only_first'` (will only truncate the first sentence in the pairs) `truncation='only_second'` (will only truncate the second sentence in the pairs) or `truncation='longest_first'` (will iteratively remove tokens from the longest sentence in the pairs).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>Who are you voting for in 2020?</s></s>This example is politics.</s>\n",
            "tensor([[    0, 12375,    32,    47,  3434,    13,    11,  2760,   116,     2,\n",
            "             2,   713,  1246,    16,  2302,     4,     2]])\n",
            "tensor([[-2.2515,  1.2416,  1.2983]], device='cuda:0')\n",
            "tensor([[-2.2515,  1.2983]], device='cuda:0')\n",
            "tensor([[0.0279, 0.9721]], device='cuda:0')\n",
            "tensor([0.9721], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}