- コーパス  

新聞やネットの記事などの文章や、話し言葉を書き起こした文章などを大量に収集し、検索や分析ができるようにしたデータベースのこと。  
注釈付きコーパスとは、単語の分割境界や品詞タグなどの情報を付加したコーパスを指す。

- 語彙

### 言語モデル
言語モデルとは、入力として文章（トークン列）を受け取り、文章の出現確率（もっともらしさ、出現しやすさ）を返す関数である。  
良いモデルは、人間がもっともらしいと感じる文章に高い確率、つまり1に近い数値を返却する。  
ニューラル言語モデルとは、ニューラルネットワークにより実現される言語モデルのこと。  

```
そもそも確率(Probability)とは、事象の起こりやすさを0以上1以下の数で表したもの。  
サイコロを振って1が出る確率をxとすると、2,3,4,5,6が出る確率も同じため（同様に確からしい、という）  
x + x + x + x + x + x = 1 が成り立ち、x = 1/6 となることからこれは理解できる。

確率の基本は、起こりうる事象を数え上げることにある。

サイコロを2回振って1回目に1、2回目に2が出る確率は、1/6 * 1/6 と覚えているが、これは分母同士の積で起こりうる事象の全パターンを数え上げ、
分子同士の積で対象の事象パターンを数え上げている。
```

言語モデルからすれば、入力された文章Sの出現確率は、Sを構成する複数のトークンが同時に出現する確率といえるため、各トークンの出現率の積を計算することになる。

各トークンの出現率だが、文章には流れ・文脈・テーマがあることから、あるトークンの出現率は、以前に出現したトークンの影響を受けることを考慮する必要がある。これには「条件付き確率」を使う。

以上から、文章Sが3つのトークンw1、w2, w3で構成される場合、文章Sの出現確率p(S)は、次のようになる。

`p(S) = p(w1,w2,w3) = p(w1) * p(w2|w1) * p(w3|w1,w2)`


### 分類器
分類器とは、入力データが与えられたとき、そのカテゴリーを予測するモデルのこと。  
モデルは、入力データとしてxを受け取り、出力としてカテゴリー数と同じ次元を持つベクトルyを返却する。  
yの中で最大値をとる次元に対応するカテゴリが答えとなる。

モデルのハイパーパラメータを決定するための評価関数（損失関数）にはクロスエントロピー誤差を用いることが多い。  
これは出力yに非線形関数のSoftMax関数を適用した後、正解となるカテゴリに対応する次元の値を確認し、良し悪しを評価する。

分類器の仕組みを言語モデルで利用すれば、ある文脈において、次に出現するトークンを予測することができる。  
つまり語彙に含まれる全てのトークン数がNであれば、カテゴリー数をNとするクラス分類と解釈すれば良い。

## ニューラル言語モデルの構築
### 基本のネットワーク構造
1. 入力層... 文脈に該当するトークン列を入力として受け取る
2. 中間層... モデルごとに様々
3. 出力層... 与えられた文脈下でのトークン出現確率分布を出力する

### 入力層
文章を、トークン毎に密な（全ての次元に意味のある値が入る）ベクトル表現に変換する。  
この変換を行う層は、埋め込み層と呼ばれる。
トークンに対応づけられたベクトルは、分散表現、あるいは埋め込み表現（embedding）と呼ばれる。




### 出力層
